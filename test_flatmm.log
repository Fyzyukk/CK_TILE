Launching kernel with args:tile_gemm_shape_128x128x64x4_1x4x1_16x16x32
Shape: tile_gemm_shape_128x128x64x4_1x4x1_16x16x32
problem: gemm_problem_256_0x0x0_Default
pipeline: pipeline_AGmemBGmemCRegV1_128x128x64x256_8x8_0x0x0
grid: {4, 1, 1}, blocks: {256, 1, 1}
Flushing cache...
RotatingMemWrapper: { size_a: 65536, size_b: 65536, rotating_count: 10}
开始测试 ck_tile_python GEMM 模块
==================================================
✅ CUDA 可用，设备: AMD Instinct MI308X
==================================================
测试模块导入...
成功导入 ck_tile_python 模块
可用函数: ['BatchedGemmArgs', 'FlatmmArgs', 'GemmArgs', 'GroupGemmArgs', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'batched_gemm_api', 'flatmm_api', 'gemm_api', 'grouped_gemm_api']
==================================================
测试 FlatmmArgs 结构...
参数创建成功:
  Ms: 256
  Ns: 256
  Ks: 128
  dtype: fp16
==================================================
创建测试张量...
矩阵尺寸: A(256x128), B(128x256) -> C(256x256)
A tensor: shape=torch.Size([256, 128]), stride=(128, 1)
B tensor: shape=torch.Size([128, 256]), stride=(256, 1)
==================================================
测试 flatmm_api 函数...
执行成功！耗时: 0.0264 秒
返回结果张量形状: torch.Size([256, 256])
期望形状 (256, 256), 实际形状 (256, 256)
✅ 形状正确
==================================================
验证结果正确性...
❌ 结果不正确
  最大差异: 73.125000
  平均差异: 12.281250
❌ 验证失败，结果不正确
