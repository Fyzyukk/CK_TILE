#!/usr/bin/env python3
"""
è°ƒè¯• Batched GEMM çš„æ­¥é•¿å’Œå¸ƒå±€é—®é¢˜
"""

import torch
import ck_tile_python
import numpy as np

def debug_stride_and_layout():
    """è°ƒè¯•æ­¥é•¿å’Œå¸ƒå±€é—®é¢˜"""
    print("=" * 60)
    print("è°ƒè¯• Batched GEMM æ­¥é•¿å’Œå¸ƒå±€é—®é¢˜")
    print("=" * 60)
    
    # åˆ›å»ºå°è§„æ¨¡çš„æµ‹è¯•æ•°æ®
    batch_count, M, N, K = 2, 4, 4, 4
    dtype = torch.float16
    
    print(f"æµ‹è¯•è§„æ ¼: batch_count={batch_count}, M={M}, N={N}, K={K}")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    A = torch.arange(batch_count * M * K, dtype=dtype, device='cuda').reshape(batch_count, M, K)
    B = torch.arange(batch_count * K * N, dtype=dtype, device='cuda').reshape(batch_count, K, N)
    
    print(f"\nA tensor:")
    print(f"  shape: {A.shape}")
    print(f"  stride: {A.stride()}")
    print(f"  data: {A.cpu().numpy()}")
    
    print(f"\nB tensor:")
    print(f"  shape: {B.shape}")
    print(f"  stride: {B.stride()}")
    print(f"  data: {B.cpu().numpy()}")
    
    # ä½¿ç”¨ PyTorch è®¡ç®—å‚è€ƒç»“æœ
    expected = torch.bmm(A, B)
    print(f"\nPyTorch å‚è€ƒç»“æœ:")
    print(f"  shape: {expected.shape}")
    print(f"  data: {expected.cpu().numpy()}")
    
    # åˆ›å»ºå‚æ•°
    args = ck_tile_python.BatchedGemmArgs()
    args.Ms = M
    args.Ns = N
    args.Ks = K
    args.batched_count = batch_count
    args.dtype = "fp16"
    args.validate = False
    args.warmup = 1
    args.repeat = 1
    
    # è°ƒç”¨æˆ‘ä»¬çš„å®ç°
    try:
        result = ck_tile_python.batched_gemm_api(A, B, args)
        print(f"\nck_tile_python ç»“æœ:")
        print(f"  shape: {result.shape}")
        print(f"  data: {result.cpu().numpy()}")
        
        # æ¯”è¾ƒç»“æœ
        diff = torch.abs(result - expected)
        max_diff = torch.max(diff).item()
        mean_diff = torch.mean(diff).item()
        
        print(f"\nå·®å¼‚åˆ†æ:")
        print(f"  æœ€å¤§å·®å¼‚: {max_diff:.6f}")
        print(f"  å¹³å‡å·®å¼‚: {mean_diff:.6f}")
        
        if max_diff < 1e-3:
            print("  âœ… ç»“æœæ­£ç¡®")
        else:
            print("  âŒ ç»“æœä¸æ­£ç¡®")
            print(f"  è¯¦ç»†å·®å¼‚: {diff.cpu().numpy()}")
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def debug_stride_calculation():
    """è°ƒè¯•æ­¥é•¿è®¡ç®—"""
    print("=" * 60)
    print("è°ƒè¯•æ­¥é•¿è®¡ç®—")
    print("=" * 60)
    
    M, N, K = 4, 4, 4
    
    # æ¨¡æ‹Ÿ ck_tile::get_default_stride çš„è®¡ç®—
    # Row major: stride = col
    # Column major: stride = row
    
    stride_A_row = K  # Row major: M x K, stride = K
    stride_B_col = K  # Column major: K x N, stride = K  
    stride_C_row = N  # Row major: M x N, stride = N
    
    print(f"æ­¥é•¿è®¡ç®—:")
    print(f"  A (Row Major, M={M} x K={K}): stride = {stride_A_row}")
    print(f"  B (Column Major, K={K} x N={N}): stride = {stride_B_col}")
    print(f"  C (Row Major, M={M} x N={N}): stride = {stride_C_row}")
    
    # æ‰¹æ¬¡æ­¥é•¿
    batch_stride_A = M * K
    batch_stride_B = K * N
    batch_stride_C = M * N
    
    print(f"\næ‰¹æ¬¡æ­¥é•¿:")
    print(f"  batch_stride_A = M * K = {M} * {K} = {batch_stride_A}")
    print(f"  batch_stride_B = K * N = {K} * {N} = {batch_stride_B}")
    print(f"  batch_stride_C = M * N = {M} * {N} = {batch_stride_C}")

def debug_tensor_layout():
    """è°ƒè¯•å¼ é‡å¸ƒå±€"""
    print("=" * 60)
    print("è°ƒè¯•å¼ é‡å¸ƒå±€")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¼ é‡
    A = torch.randn(2, 4, 4, dtype=torch.float16, device='cuda')
    B = torch.randn(2, 4, 4, dtype=torch.float16, device='cuda')
    
    print(f"A tensor (Row Major):")
    print(f"  shape: {A.shape}")
    print(f"  stride: {A.stride()}")
    print(f"  is_contiguous: {A.is_contiguous()}")
    
    # è½¬ç½® B çŸ©é˜µä¸º Column Major
    B_col = B.transpose(-2, -1).contiguous()
    print(f"\nB tensor (Column Major):")
    print(f"  shape: {B_col.shape}")
    print(f"  stride: {B_col.stride()}")
    print(f"  is_contiguous: {B_col.is_contiguous()}")
    
    # æ¯”è¾ƒç»“æœ
    result1 = torch.bmm(A, B)  # åŸå§‹ B
    result2 = torch.bmm(A, B_col)  # è½¬ç½®åçš„ B
    
    print(f"\nç»“æœæ¯”è¾ƒ:")
    print(f"  torch.bmm(A, B): {result1.cpu().numpy()}")
    print(f"  torch.bmm(A, B_col): {result2.cpu().numpy()}")
    
    diff = torch.abs(result1 - result2)
    max_diff = torch.max(diff).item()
    print(f"  æœ€å¤§å·®å¼‚: {max_diff:.6f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹è°ƒè¯• Batched GEMM")
    
    # æ£€æŸ¥ CUDA å¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âŒ CUDA ä¸å¯ç”¨")
        return
    
    # è°ƒè¯•æ­¥é•¿è®¡ç®—
    debug_stride_calculation()
    
    # è°ƒè¯•å¼ é‡å¸ƒå±€
    debug_tensor_layout()
    
    # è°ƒè¯•å®Œæ•´æµç¨‹
    debug_stride_and_layout()

if __name__ == "__main__":
    main()
